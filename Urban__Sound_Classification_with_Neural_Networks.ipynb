{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Urban _Sound_Classification_with_Neural_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2R6wRwFGFfV"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "if 'drive' in os.listdir():\n",
        "  directory = 'drive/MyDrive/UrbanSound/'\n",
        "else:\n",
        "  directory = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WDCmFBcblWH"
      },
      "source": [
        "# Download and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTmWOWt4Zpks"
      },
      "source": [
        "!wget -c https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHA0rAlody1g"
      },
      "source": [
        "!tar -xf UrbanSound8K.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBGY5u56d8nN"
      },
      "source": [
        "!rm UrbanSound8K.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcfua3d4efdm"
      },
      "source": [
        "!pip install librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIMRYBIXbq_S"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svV6ZnwrgIXg"
      },
      "source": [
        "#Just some metadata EDA\n",
        "import pandas as pd\n",
        "\n",
        "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
        "metadata.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlBVHGuYg9aJ"
      },
      "source": [
        "metadata['class'].isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGE_KqHChFRT"
      },
      "source": [
        "metadata['slice_file_name'].isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoNNYRitnM2l"
      },
      "source": [
        "metadata.set_index('slice_file_name',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92jR_AzAhJeg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "metadata['class'].value_counts().plot.pie()\n",
        "plt.savefig('class-pie.pdf',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7FQ5KG5YsV5"
      },
      "source": [
        "sample_rate = 44100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlhyFsAppQEO"
      },
      "source": [
        "from os import listdir\n",
        "import librosa\n",
        "\n",
        "raw_sounds = []\n",
        "\n",
        "for fold in range(1,11):\n",
        "  path = f'UrbanSound8K/audio/fold{fold}/'\n",
        "  for file in listdir(path):\n",
        "    if \"wav\" in file:\n",
        "      file_path = path + file\n",
        "      sound_file, sr = librosa.load(file_path, sr = sample_rate) #load raw sound from sound files\n",
        "      #print((file,sound_file,train_labels.loc[file]['classID']))\n",
        "      row = metadata.loc[file]\n",
        "      raw_sounds.append((file,sound_file,row['fold'],row['classID']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaG4xx-ttp6k"
      },
      "source": [
        "#SOUND FEATURE EXTRACTION\n",
        "import numpy as np\n",
        "\n",
        "hop_length = 256\n",
        "frame_length = 512\n",
        "\n",
        "features = []\n",
        "\n",
        "for name,sound,fold,classid in raw_sounds:\n",
        "  mfcc_coefficients = np.mean(librosa.feature.mfcc(y=sound, sr=sample_rate, n_mfcc=20).T,axis=0)\n",
        "  stft = np.abs(librosa.stft(sound))\n",
        "  chromas = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "  zcr = np.mean(librosa.feature.zero_crossing_rate(sound,hop_length=hop_length,frame_length=frame_length))\n",
        "  rms = librosa.feature.rms(sound, frame_length=frame_length, hop_length=hop_length, center=True)[0]\n",
        "  rms_mean = np.mean(rms)\n",
        "  rms_std = np.std(rms)\n",
        "  rms_min = np.min(rms)\n",
        "  rms_max = np.max(rms)\n",
        "  features.append(np.hstack(([name],mfcc_coefficients,chromas,[zcr],[rms_mean,rms_std,rms_min,rms_max],[fold,classid])))\n",
        "\n",
        "dfsound = pd.DataFrame(features, columns= ['slice_file_name'] \\\n",
        "                          + [f'mfcc_{i}' for i in range(len(mfcc_coefficients))] \\\n",
        "                          + [f'chroma_{i}' for i in range(len(chromas))] \\\n",
        "                          + ['zcr'] \\\n",
        "                          + ['rms_mean','rms_std','rms_min','rms_max'] + ['fold','classID'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5_xJ54exqFY"
      },
      "source": [
        "import pandas as pd\n",
        "#dfsound contain slice_file_name, sound features, classID\n",
        "dfsound.to_csv('urbansound_features.csv',index=False)\n",
        "dfsound = pd.read_csv(directory+'urbansound_features.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqPeMHkBns2I"
      },
      "source": [
        "dfsound.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt6FnJaYmrU2"
      },
      "source": [
        "#Train the model on folds: 1, 2, 3, 4, 6, and test it on folds: 5, 7, 8, 9, 10\n",
        "\n",
        "train_folds = [1,2,3,4,6]\n",
        "test_folds = [5,7,8,9,10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIRrz_BASfbl"
      },
      "source": [
        "#SPECTOGRAM CONSTRUCTION\n",
        "import os\n",
        "import math\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cmap = plt.get_cmap('inferno')\n",
        "plt.figure(figsize=(8,8))\n",
        "count = 0\n",
        "sample_rate = 44100\n",
        "\n",
        "for fold in range(1,11):\n",
        "  path = f'UrbanSound8K/audio/fold{fold}/'\n",
        "  for file in os.listdir(path):\n",
        "    if \"wav\" in file:\n",
        "        file_path = path + file\n",
        "        y, sr = librosa.load(file_path, sr = sample_rate)\n",
        "        #print(y.shape)\n",
        "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
        "        plt.axis('off');\n",
        "\n",
        "        try:\n",
        "          os.mkdir(f'UrbanSound8K/img_data/')\n",
        "        except FileExistsError:\n",
        "          pass\n",
        "        try:\n",
        "          os.mkdir(f'UrbanSound8K/img_data/fold{fold}')\n",
        "        except FileExistsError:\n",
        "          pass\n",
        "        \n",
        "        plt.savefig(f'UrbanSound8K/img_data/fold{fold}/{file[:-4]}.png',transparent=True, pad_inches=0.0)\n",
        "        plt.clf()\n",
        "\n",
        "        count += 1\n",
        "        if count % 1000 == 0:\n",
        "          print(\"Processed \", count, \" files\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwDP-wDQYXXD"
      },
      "source": [
        "#NORMALIZATION\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train = dfsound[dfsound['fold'].isin(train_folds)]\n",
        "test = dfsound[dfsound['fold'].isin(test_folds)]\n",
        "\n",
        "data_train = train.drop(['slice_file_name','fold','classID'],axis=1)\n",
        "data_test = test.drop(['slice_file_name','fold','classID'],axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(data_train)\n",
        "X_test = scaler.fit_transform(data_test)\n",
        "y_train = train['classID']\n",
        "y_test = test['classID']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXlgW2FH9Xz6"
      },
      "source": [
        "#TRAIN TEST SPLIT\n",
        "test_per_fold = [test[test['fold']==f] for f in test_folds]\n",
        "data_test_per_fold = list(map(lambda df: df.drop(['slice_file_name','fold','classID'],axis=1),test_per_fold))\n",
        "X_test_per_fold = list(map(lambda data: scaler.fit_transform(data),data_test_per_fold))\n",
        "y_test_per_fold = list(map(lambda df: df['classID'],test_per_fold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49OE6lvwtoq3"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "validation_data = (X_test,y_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw7uSa0WSK6q"
      },
      "source": [
        "# Audio Player utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyQGL7NGOsIA"
      },
      "source": [
        "\"\"\"\n",
        "import IPython.display as ipd\n",
        "numTrack = 0 #number of track in dfsound dataset\n",
        "nameTrack = dfsound['slice_file_name'][numTrack]\n",
        "fold = dfsound[dfsound['slice_file_name']==nameTrack]['fold'].values[0]\n",
        "fpath = f'UrbanSound8K/audio/fold{fold}/{nameTrack}'\n",
        "ipd.Audio(fpath)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n4tqC-VcxUN"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlDCXvCNEiy1"
      },
      "source": [
        "#Some imports and plot settings\n",
        "%matplotlib inline\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import os, re, math, json, shutil, pprint\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "from google.colab import output\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "np.set_printoptions(precision=3, threshold=11)\n",
        "\n",
        "# Matplotlib config\n",
        "plt.style.use('seaborn')\n",
        "# Matplotlib fonts\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__),\n",
        "                                   \"mpl-data/fonts/ttf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV50u1iIc1wW"
      },
      "source": [
        "## FFNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw4SB8aO9iHR"
      },
      "source": [
        "num_class = len(dfsound['classID'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0RXQVdsROk_"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "NUM_EPOCH = 100\n",
        "BATCH_SIZE = 128\n",
        "SAMPLE_SIZE = len(dfsound)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7kMPfo7RWLM"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oEnibVhoW1z"
      },
      "source": [
        "### Zero hidden-layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwYCoKrhkPea"
      },
      "source": [
        "history_ffnn = []\n",
        "ffnn_labels = ['0hidden','1-hidden','2-hidden','3-hidden']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k66KGENM4gFg"
      },
      "source": [
        "ffnn_0hidden = Sequential()\n",
        "ffnn_0hidden.add(layers.Input(shape=(X_train.shape[1],)))\n",
        "ffnn_0hidden.add(layers.Dense(num_class, activation='softmax'))\n",
        "ffnn_0hidden.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ffnn_0hidden.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDxHuEGA94d9"
      },
      "source": [
        "history = ffnn_0hidden.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=NUM_EPOCH,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=validation_data,\n",
        "                    validation_steps=1,\n",
        "                    callbacks = [early_stopping]\n",
        "                    )\n",
        "history_ffnn.append(history)       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXyUvC510cgn"
      },
      "source": [
        "ITOFOLD = {i:str(tf) for i,tf in zip(range(0,len(test_folds)),test_folds)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6gl3sIM0UC9"
      },
      "source": [
        "def evaluate_on_test_folds(model,X_test_per_fold,y_test_per_fold):\n",
        "  \"\"\"\n",
        "    Given the test folds returns the distribution of the accuracies along them.\n",
        "  \"\"\"\n",
        "  accuracies = []\n",
        "  for X_test,y_test in zip(X_test_per_fold,y_test_per_fold):\n",
        "    _,acc = model.evaluate(X_test,y_test, batch_size=BATCH_SIZE)\n",
        "    accuracies.append(acc)\n",
        "  return accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LSDpdwp4Cg5"
      },
      "source": [
        "x = list(ITOFOLD.values())\n",
        "accuracies = evaluate_on_test_folds(ffnn_0hidden,X_test_per_fold,y_test_per_fold)\n",
        "plt.barh(x,accuracies,color='#ff7f0e')\n",
        "plt.xlabel('accuracy')\n",
        "plt.ylabel('test fold')\n",
        "plt.savefig('ffnn_0hidden_acc_test_folds.pdf',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoh-ylx36Oov"
      },
      "source": [
        "print(f'Avg accuracy: {np.mean(accuracies)}')\n",
        "print(f'Std accuracy: {np.std(accuracies)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHgBOB1NAW2X"
      },
      "source": [
        "### One hidden-layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_qNmlxGPslg"
      },
      "source": [
        "# lr decay function\n",
        "def lr_decay(epoch):\n",
        "  return 0.01 * math.pow(0.95, epoch)\n",
        "\n",
        "# lr schedule callback\n",
        "lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)\n",
        "\n",
        "def plot_learning_rate(lr_func, epochs):\n",
        "  xx = np.arange(epochs+1, dtype=np.float)\n",
        "  y = [lr_decay(x) for x in xx]\n",
        "  fig, ax = plt.subplots(figsize=(9, 6))\n",
        "  ax.set_xlabel('epochs')\n",
        "  ax.set_title('Learning rate\\ndecays from {:0.3g} to {:0.3g}'.format(y[0],\n",
        "                                                                      y[-2]))\n",
        "  ax.minorticks_on()\n",
        "  ax.grid(True, which='major', axis='both', linestyle='-', linewidth=1)\n",
        "  ax.grid(True, which='minor', axis='both', linestyle=':', linewidth=0.5)\n",
        "  ax.step(xx,y, linewidth=3, where='post')\n",
        "  plt.savefig('lr-decay.pdf',bbox_inches='tight')\n",
        "  display(fig)\n",
        "\n",
        "plot_learning_rate(lr_decay, NUM_EPOCH)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_740JyTMo39W"
      },
      "source": [
        "#One hidden-layer\n",
        "\n",
        "ffnn_1hidden = Sequential()\n",
        "ffnn_1hidden.add(layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ffnn_1hidden.add(layers.Dropout(0.25))\n",
        "ffnn_1hidden.add(layers.Dense(num_class, activation='softmax'))\n",
        "ffnn_1hidden.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ffnn_1hidden.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGeeNEtdpRhu"
      },
      "source": [
        "history = ffnn_1hidden.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=NUM_EPOCH,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=validation_data,\n",
        "                    validation_steps=1,\n",
        "                    callbacks=[lr_decay_callback,early_stopping])\n",
        "\n",
        "history_ffnn.append(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PrKQCQA7aNw"
      },
      "source": [
        "x = list(ITOFOLD.values())\n",
        "accuracies = evaluate_on_test_folds(ffnn_1hidden,X_test_per_fold,y_test_per_fold)\n",
        "plt.barh(x,accuracies,color='#ff7f0e')\n",
        "plt.xlabel('accuracy')\n",
        "plt.ylabel('test fold')\n",
        "plt.savefig('ffnn1hidden_acc_test_folds.pdf',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwFEACJ_AP4O"
      },
      "source": [
        "print(f'Avg accuracy: {np.mean(accuracies)}')\n",
        "print(f'Std accuracy: {np.std(accuracies)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9-KxypwApRL"
      },
      "source": [
        "### Two hidden-layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmkGcrK1kCtm"
      },
      "source": [
        "#two hidden-layer\n",
        "\n",
        "ffnn_2hidden = Sequential()\n",
        "ffnn_2hidden.add(layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ffnn_2hidden.add(layers.Dropout(0.25))\n",
        "ffnn_2hidden.add(layers.Dense(24, activation='relu'))\n",
        "ffnn_2hidden.add(layers.Dropout(0.25))\n",
        "ffnn_2hidden.add(layers.Dense(num_class, activation='softmax'))\n",
        "ffnn_2hidden.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ffnn_2hidden.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2UQjn7-H9kz"
      },
      "source": [
        "history = ffnn_2hidden.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=NUM_EPOCH,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=validation_data,\n",
        "                    validation_steps=1,\n",
        "                    callbacks = [lr_decay_callback,early_stopping]\n",
        "                    )\n",
        "\n",
        "history_ffnn.append(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEP473WtIYfy"
      },
      "source": [
        "x = list(ITOFOLD.values())\n",
        "accuracies = evaluate_on_test_folds(ffnn_2hidden,X_test_per_fold,y_test_per_fold)\n",
        "plt.barh(x,accuracies,color='#ff7f0e')\n",
        "plt.xlabel('accuracy')\n",
        "plt.ylabel('test fold')\n",
        "plt.savefig('ffnn2hidden_acc_test_folds.pdf',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFxZdgBKIcbI"
      },
      "source": [
        "print(f'Avg accuracy: {np.mean(accuracies)}')\n",
        "print(f'Std accuracy: {np.std(accuracies)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZrJR1xaQFDz"
      },
      "source": [
        "### Three hidden-layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfczT9DYQH0N"
      },
      "source": [
        "#three hidden-layer\n",
        "\n",
        "ffnn_3hidden = Sequential()\n",
        "ffnn_3hidden.add(layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ffnn_3hidden.add(layers.Dropout(0.25))\n",
        "ffnn_3hidden.add(layers.Dense(24, activation='relu'))\n",
        "ffnn_3hidden.add(layers.Dropout(0.25))\n",
        "ffnn_3hidden.add(layers.Dense(16, activation='relu'))\n",
        "ffnn_3hidden.add(layers.Dropout(0.25))\n",
        "ffnn_3hidden.add(layers.Dense(num_class, activation='softmax'))\n",
        "ffnn_3hidden.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ffnn_3hidden.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCJBZI0EQS3F"
      },
      "source": [
        "history = ffnn_3hidden.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=NUM_EPOCH,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=validation_data,\n",
        "                    validation_steps=1,\n",
        "                    callbacks = [lr_decay_callback,early_stopping]\n",
        "                    )\n",
        "\n",
        "history_ffnn.append(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2Ay0T4BQQAl"
      },
      "source": [
        "x = list(ITOFOLD.values())\n",
        "accuracies = evaluate_on_test_folds(ffnn_3hidden,X_test_per_fold,y_test_per_fold)\n",
        "plt.barh(x,accuracies,color='#ff7f0e')\n",
        "plt.xlabel('accuracy')\n",
        "plt.ylabel('test fold')\n",
        "plt.savefig('ffnn3hidden_acc_test_folds.pdf',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKsmCoCAQc3M"
      },
      "source": [
        "print(f'Avg accuracy: {np.mean(accuracies)}')\n",
        "print(f'Std accuracy: {np.std(accuracies)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIMBq0oQ8jXr"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "for i in range(1,4):\n",
        "    plt.plot(history_ffnn[i].history['val_accuracy'])  \n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(ffnn_labels[1:], loc='upper left')\n",
        "plt.savefig('ffnn_val_acc.pdf')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWME6UIzAt9b"
      },
      "source": [
        "### Dimensionality reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNFgZ3LbEzeP"
      },
      "source": [
        "#### Boruta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlxZt5jtE9Bz"
      },
      "source": [
        "!pip install boruta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biYAYhcjExbp"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "boruta_selector = BorutaPy(\n",
        "        RandomForestClassifier(n_jobs=cpu_count(), class_weight='balanced', max_depth=5),\n",
        "        n_estimators='auto',\n",
        "        verbose=2,\n",
        "        alpha=0.05, # p_value\n",
        "        max_iter=100,\n",
        "        random_state=42\n",
        ")\n",
        "\n",
        "boruta_result = boruta_selector.fit_transform(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fudbi0MXKWHX"
      },
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA1mp932KFiG"
      },
      "source": [
        "##### One for all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hSCR8UlGdwU"
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV-qpRgIAeD0"
      },
      "source": [
        "#PCA them all!\n",
        "\n",
        "X_train_pca = PCA(n_components=20).fit_transform(X_train)\n",
        "validation_data_pca = (PCA(n_components=20).fit_transform(validation_data[0]),validation_data[1])\n",
        "X_test_per_fold_pca = list(map(lambda X: PCA(n_components=20).fit_transform(X),X_test_per_fold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj2X3jcADImK"
      },
      "source": [
        "ffnn_pca = Sequential()\n",
        "ffnn_pca.add(layers.Dense(32, activation='relu', input_shape=(X_train_pca.shape[1],)))\n",
        "ffnn_pca.add(layers.Dropout(0.25))\n",
        "ffnn_pca.add(layers.Dense(24, activation='relu'))\n",
        "ffnn_pca.add(layers.Dropout(0.25))\n",
        "ffnn_pca.add(layers.Dense(num_class, activation='softmax'))\n",
        "ffnn_pca.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ffnn_pca.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqwKBIh_Da5O"
      },
      "source": [
        "history = ffnn_pca.fit(X_train_pca,\n",
        "                    y_train,\n",
        "                    epochs=NUM_EPOCH,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=validation_data_pca,\n",
        "                    validation_steps=1,\n",
        "                    callbacks = [lr_decay_callback,early_stopping]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9XqRicnEN49"
      },
      "source": [
        "x = list(ITOFOLD.values())\n",
        "accuracies = evaluate_on_test_folds(ffnn_pca,X_test_per_fold_pca,y_test_per_fold)\n",
        "plt.barh(x,accuracies,color='#ff7f0e')\n",
        "plt.xlabel('accuracy')\n",
        "plt.ylabel('test fold')\n",
        "plt.savefig('ffnnpca_acc_test_folds.pdf',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWHbgHHsF8ig"
      },
      "source": [
        "print(f'Avg accuracy: {np.mean(accuracies)}')\n",
        "print(f'Std accuracy: {np.std(accuracies)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu_NtXO-KIKj"
      },
      "source": [
        "##### Different PCAs for different features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwXQ96neF7dK"
      },
      "source": [
        "#One PCA for mfcc from 20 to 10\n",
        "#One PCA for chroma from 12 to 5\n",
        "#Concatenate mfcc, chroma, other features(zcr + rmse)\n",
        "\n",
        "def pcaSchema(X,num_mfcc = 20, num_chroma = 12):\n",
        "  X_mfcc = X[:,:num_mfcc]\n",
        "  X_pca_mfcc = PCA(n_components=10).fit_transform(X_mfcc)\n",
        "  X_chroma = X[:,num_mfcc:(num_mfcc + num_chroma)]\n",
        "  X_chroma_pca = PCA(n_components=5).fit_transform(X_chroma)\n",
        "  X_pcaSchema = np.hstack((X_pca_mfcc,X_chroma_pca,X[:,(num_mfcc+num_chroma):]))\n",
        "  return X_pcaSchema\n",
        "\n",
        "X_train_pcaSchema= pcaSchema(X_train)\n",
        "validation_data_pcaSchema = (pcaSchema(validation_data[0]),validation_data[1])\n",
        "X_test_per_fold_pcaSchema = list(map(lambda X: pcaSchema(X),X_test_per_fold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gcNCPlPJ1OF"
      },
      "source": [
        "ffnn_pcaSchema = Sequential()\n",
        "ffnn_pcaSchema.add(layers.Dense(32, activation='relu', input_shape=(X_train_pcaSchema.shape[1],)))\n",
        "ffnn_pcaSchema.add(layers.Dropout(0.25))\n",
        "ffnn_pcaSchema.add(layers.Dense(24, activation='relu'))\n",
        "ffnn_pcaSchema.add(layers.Dropout(0.25))\n",
        "ffnn_pcaSchema.add(layers.Dense(num_class, activation='softmax'))\n",
        "ffnn_pcaSchema.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ffnn_pcaSchema.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfeYby5cKZL5"
      },
      "source": [
        "history = ffnn_pcaSchema.fit(X_train_pcaSchema,\n",
        "                    y_train,\n",
        "                    epochs=NUM_EPOCH,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=validation_data_pcaSchema,\n",
        "                    validation_steps=1,\n",
        "                    callbacks = [lr_decay_callback,early_stopping]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UcKlU42KgE_"
      },
      "source": [
        "x = list(ITOFOLD.values())\n",
        "accuracies = evaluate_on_test_folds(ffnn_pcaSchema,X_test_per_fold_pcaSchema,y_test_per_fold)\n",
        "plt.barh(x,accuracies,color='#ff7f0e')\n",
        "plt.xlabel('accuracy')\n",
        "plt.ylabel('test fold')\n",
        "plt.savefig('ffnnpcaSchema_acc_test_folds.pdf',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-dcA0PlKoit"
      },
      "source": [
        "print(f'Avg accuracy: {np.mean(accuracies)}')\n",
        "print(f'Std accuracy: {np.std(accuracies)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYGqjL5fc70t"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVCA7CBqF_8F"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dfsound = pd.read_csv(directory+'urbansound_features.csv')\n",
        "dfsound.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6NdQblTGo-6"
      },
      "source": [
        "#!unzip drive/MyDrive/UrbanSound/UrbanSound_img.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAQYlRONpJ_9"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array,array_to_img\n",
        "\n",
        "def getTFDataset(numFold,metadata):\n",
        "    \"\"\"\n",
        "      Given the id of a certain fold and the metadata file,\n",
        "      it returns the vectorial representation of the spectogram files in the fold along with their labels\n",
        "    \"\"\"\n",
        "    pathFold = f'UrbanSound8K/img_data/fold{numFold}/'\n",
        "    img = []\n",
        "    labels = []\n",
        "\n",
        "    for file in os.listdir(pathFold):\n",
        "      if 'png' not in file: continue\n",
        "      image_path = pathFold+file\n",
        "      image = load_img(image_path,target_size=(64,64))\n",
        "      x = img_to_array(image)\n",
        "      filename = file.split('.')[0]\n",
        "      wav = filename + '.wav'\n",
        "      y = metadata[metadata['slice_file_name']==wav]['classID'].values[0]\n",
        "      img.append(x)\n",
        "      labels.append(y)\n",
        "    \n",
        "    return img,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu2pjBG4vPGv"
      },
      "source": [
        "#Specgram train set construction\n",
        "import numpy as np\n",
        "\n",
        "train_img, train_labels = [],[]\n",
        "for numFold in train_folds:\n",
        "  img,labels = getTFDataset(numFold,dfsound)\n",
        "  train_img  = train_img + img\n",
        "  train_labels = train_labels + labels\n",
        "\n",
        "train_img = np.asarray(train_img)\n",
        "train_labels = np.asarray(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0fBM0uJW8xx"
      },
      "source": [
        "#Specgram test set construction\n",
        "test_img_per_fold, test_labels_per_fold = [],[]\n",
        "\n",
        "for numFold in test_folds:\n",
        "  img,labels = getTFDataset(numFold,dfsound)\n",
        "  test_img_per_fold.append(img)\n",
        "  test_labels_per_fold.append(labels)\n",
        "\n",
        "test_img_per_fold = list(map(lambda x: np.asarray(x),test_img_per_fold))\n",
        "test_labels_per_fold = list(map(lambda x: np.asarray(x),test_labels_per_fold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2NcrjqDXOno"
      },
      "source": [
        "validation_img = [e for f in test_img_per_fold for e in f]\n",
        "validation_labels = [e for y in test_labels_per_fold for e in y]\n",
        "validation_data_img = (np.asarray(validation_img),np.asarray(validation_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJGrZKhDao7V"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "#ARCHITECTURES: 1 / 2 / 3 Conv2D Layers with 16 / 32 / 64 neurons + 32 / 64 / 128 Dense hidden neurons\n",
        "\n",
        "num_conv2d_layers = [1,2,3]\n",
        "num_conv2d_neurons = [16,32,64]\n",
        "num_dense_neurons = [32,64,128]\n",
        "\n",
        "cnns_labels = []\n",
        "cnns = []\n",
        "\n",
        "assert(len(num_conv2d_layers) == len(num_dense_neurons))\n",
        "\n",
        "for num_layers in num_conv2d_layers:\n",
        "  for num_dense in num_dense_neurons:\n",
        "    cnns_labels.append(f'{num_layers}Conv2D_{num_dense}Dense')\n",
        "    cnn = Sequential()\n",
        "    cnn.add(layers.Rescaling(1./255,input_shape=(64,64,3)))\n",
        "    for i in range(num_layers):\n",
        "      cnn.add(layers.Conv2D(num_conv2d_neurons[i],3,padding='same',activation='relu'))\n",
        "      cnn.add(layers.MaxPooling2D())\n",
        "    cnn.add(layers.Flatten())\n",
        "    cnn.add(layers.Dense(num_dense,activation='relu'))\n",
        "    cnn.add(layers.Dense(10,activation='softmax'))\n",
        "    cnn.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    cnns.append(cnn)\n",
        "\n",
        "history_cnn = []\n",
        "for i in range(len(num_conv2d_layers)*len(num_dense_neurons)):\n",
        "  print(f'{cnns_labels[i]} START')\n",
        "  history = cnns[i].fit(train_img,\n",
        "                    train_labels,\n",
        "                    epochs=NUM_EPOCH,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data = validation_data_img,\n",
        "                    validation_steps = 1,\n",
        "                    callbacks = [early_stopping]\n",
        "                    )         \n",
        "  print(f'{cnns_labels[i]} END')\n",
        "  print()\n",
        "  history_cnn.append(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k922Pe333wu"
      },
      "source": [
        "x = list(ITOFOLD.values())\n",
        "for i in range(len(num_conv2d_layers)*len(num_dense_neurons)):\n",
        "  accuracies = evaluate_on_test_folds(cnns[i],test_img_per_fold,test_labels_per_fold)\n",
        "  plt.barh(x,accuracies,color='#ff7f0e')\n",
        "  plt.xlabel('accuracy')\n",
        "  plt.ylabel('test fold')\n",
        "  plt.savefig(f'{cnns_labels[i]}.pdf',bbox_inches='tight')\n",
        "  plt.show()\n",
        "  print(f'{cnns_labels[i]}')\n",
        "  print(f'Avg accuracy: {np.mean(accuracies)}')\n",
        "  print(f'Std accuracy: {np.std(accuracies)}')\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRN3kspZ6D8x"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "for i in range(6,9):\n",
        "    plt.plot(history_cnn[i].history['val_accuracy'])  \n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(cnns_labels[6:9], loc='upper left')\n",
        "plt.savefig('CNN_3Conv2D_val_acc.pdf')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J3gX-S6-__a"
      },
      "source": [
        "### Choose kernel size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek4gRRj2_DAY"
      },
      "source": [
        "x = list(ITOFOLD.values())\n",
        "acc_ks = []\n",
        "for ks in range(1,6): #grid search on kernel size in range [1,5]\n",
        "  print(f'KS = {ks} start')\n",
        "  cnn = Sequential()\n",
        "  cnn.add(layers.Rescaling(1./255,input_shape=(64,64,3)))\n",
        "  cnn.add(layers.Conv2D(16,ks,padding='same',activation='relu'))\n",
        "  cnn.add(layers.MaxPooling2D())\n",
        "  cnn.add(layers.Conv2D(32,ks,padding='same',activation='relu'))\n",
        "  cnn.add(layers.MaxPooling2D())\n",
        "  cnn.add(layers.Conv2D(64,ks,padding='same',activation='relu'))\n",
        "  cnn.add(layers.MaxPooling2D())\n",
        "  cnn.add(layers.Flatten())\n",
        "  cnn.add(layers.Dense(128,activation='relu'))\n",
        "  cnn.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "  cnn.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  history = cnn.fit(train_img,\n",
        "                    train_labels,\n",
        "                    epochs=NUM_EPOCH,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data = validation_data_img,\n",
        "                    validation_steps = 1,\n",
        "                    callbacks = [early_stopping]\n",
        "                    )\n",
        "  \n",
        "  accuracies = evaluate_on_test_folds(cnn,test_img_per_fold,test_labels_per_fold)\n",
        "  plt.barh(x,accuracies,color='#ff7f0e')\n",
        "  plt.xlabel('accuracy')\n",
        "  plt.ylabel('test fold')\n",
        "  plt.savefig(f'cnn_ks{ks}.pdf',bbox_inches='tight')\n",
        "  plt.show()\n",
        "  print(f'kernel-size: {ks}')\n",
        "  print(f'Avg accuracy: {np.mean(accuracies)}')\n",
        "  print(f'Std accuracy: {np.std(accuracies)}')\n",
        "  acc_ks.append(np.mean(accuracies))\n",
        "  print()\n",
        "  print(f'KS = {ks} END')\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7oglpbLHaFZ"
      },
      "source": [
        "plt.plot(range(1,6),acc_ks)\n",
        "plt.xlabel('kernel-size')\n",
        "plt.ylabel('accuracy')\n",
        "plt.savefig('CNN_kernel-size_acc.pdf',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfO6irEVc9yK"
      },
      "source": [
        "## MMNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyYVFclaeRE5"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "\n",
        "#FFNN\n",
        "\n",
        "input_ffnn =  layers.Input(shape=(X_train.shape[1]), name=\"features_data\")\n",
        "hidden = layers.Dense(32,activation='relu')(input_ffnn)\n",
        "dropout = layers.Dropout(0.25)(hidden)\n",
        "hidden = layers.Dense(24, activation='relu')(dropout)\n",
        "dropout = layers.Dropout(0.25)(hidden)\n",
        "last_hidden_ffnn = dropout\n",
        "\n",
        "\n",
        "#CNN\n",
        "\n",
        "input_cnn = layers.Input(shape=(64,64,3), name = 'specgram_data')\n",
        "rescaling = layers.Rescaling(1./255)(input_cnn)\n",
        "conv2d = layers.Conv2D(16,3,padding='same',activation='relu')(rescaling)\n",
        "pooling = layers.MaxPooling2D()(conv2d)\n",
        "conv2d = layers.Conv2D(32,3,padding='same',activation='relu')(pooling)\n",
        "pooling = layers.MaxPooling2D()(conv2d)\n",
        "conv2d = layers.Conv2D(64,3,padding='same',activation='relu')(pooling)\n",
        "pooling = layers.MaxPooling2D()(conv2d)\n",
        "flatten = layers.Flatten()(pooling)\n",
        "last_hidden_cnn = layers.Dense(128,activation='relu')(flatten)\n",
        "\n",
        "#MMNN\n",
        "concatenate = layers.Concatenate()([last_hidden_ffnn,last_hidden_cnn])\n",
        "last_hidden_mmnn = layers.Dense(64,activation='relu')(concatenate)\n",
        "output_mmnn = layers.Dense(10,activation='softmax')(last_hidden_mmnn)\n",
        "\n",
        "mmnn = Model(\n",
        "  inputs=[input_ffnn, input_cnn],\n",
        "  outputs=output_mmnn,\n",
        "  name=\"MMNN\"\n",
        ")\n",
        "\n",
        "mmnn.compile(\n",
        "  optimizer=\"adam\",\n",
        "  loss=\"sparse_categorical_crossentropy\",\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "mmnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmCfE95ZXq19"
      },
      "source": [
        "X_mmnn = {\n",
        "    'features_data': X_train,\n",
        "    'specgram_data': train_img\n",
        "}\n",
        "\n",
        "y_mmnn = y_train\n",
        "\n",
        "validation_mmnn = ({\n",
        "    'features_data': validation_data[0],\n",
        "    'specgram_data': validation_data_img[0]\n",
        "}, validation_data[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5C25XJPe2iv"
      },
      "source": [
        "history = mmnn.fit(X_mmnn,\n",
        "                    y_mmnn,\n",
        "                    epochs=40,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data = validation_mmnn,\n",
        "                    validation_steps = 1,\n",
        "                    callbacks = []\n",
        "                    )         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6dahryDgKPk"
      },
      "source": [
        "test_mmnn_per_fold = []\n",
        "labels_mmnn_per_fold = []\n",
        "for xf,xs,y in zip(X_test_per_fold,test_img_per_fold,y_test_per_fold):\n",
        "  test_mmnn_per_fold.append(\n",
        "      {\n",
        "      'features_data': xf,\n",
        "      'specgram_data': xs\n",
        "  })\n",
        "  labels_mmnn_per_fold.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSq-4kkGjM9K"
      },
      "source": [
        "x = list(ITOFOLD.values())\n",
        "accuracies = evaluate_on_test_folds(mmnn,test_mmnn_per_fold,labels_mmnn_per_fold)\n",
        "plt.barh(x,accuracies,color='#ff7f0e')\n",
        "plt.xlabel('accuracy')\n",
        "plt.ylabel('test fold')\n",
        "plt.savefig('mmnn_acc.pdf',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVvxNLJZgw5d"
      },
      "source": [
        "print(f'Avg accuracy: {np.mean(accuracies)}')\n",
        "print(f'Std accuracy: {np.std(accuracies)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUNNlELdjxj8"
      },
      "source": [
        "ffnn_2hidden = Sequential()\n",
        "ffnn_2hidden.add(layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ffnn_2hidden.add(layers.Dropout(0.25))\n",
        "ffnn_2hidden.add(layers.Dense(24, activation='relu'))\n",
        "ffnn_2hidden.add(layers.Dropout(0.25))\n",
        "ffnn_2hidden.add(layers.Dense(num_class, activation='softmax'))\n",
        "ffnn_2hidden.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ffnn_2hidden.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C9TU7QWj-HJ"
      },
      "source": [
        "history2hidden = ffnn_2hidden.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=validation_data,\n",
        "                    validation_steps=1,\n",
        "                    callbacks = [lr_decay_callback]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K05TF9tKkMKo"
      },
      "source": [
        "best_cnn = Sequential()\n",
        "best_cnn.add(layers.Rescaling(1./255,input_shape=(64,64,3)))\n",
        "best_cnn.add(layers.Conv2D(16,3,padding='same',activation='relu'))\n",
        "best_cnn.add(layers.MaxPooling2D())\n",
        "best_cnn.add(layers.Conv2D(32,3,padding='same',activation='relu'))\n",
        "best_cnn.add(layers.MaxPooling2D())\n",
        "best_cnn.add(layers.Conv2D(64,3,padding='same',activation='relu'))\n",
        "best_cnn.add(layers.MaxPooling2D())\n",
        "best_cnn.add(layers.Flatten())\n",
        "best_cnn.add(layers.Dense(128,activation='relu'))\n",
        "best_cnn.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "best_cnn.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "history_bestcnn = best_cnn.fit(train_img,\n",
        "                    train_labels,\n",
        "                    epochs=40,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data = validation_data_img,\n",
        "                    validation_steps = 1,\n",
        "                    callbacks = []\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTCkMSm8jokI"
      },
      "source": [
        "nnlabels = ['MMNN','FFNN','CNN']\n",
        "plt.figure(figsize=(15,5))\n",
        "for h in [history,history2hidden,history_bestcnn]:\n",
        "    plt.plot(h.history['val_accuracy'])  \n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(nnlabels, loc='upper left')\n",
        "plt.savefig('best_nn_acc.pdf',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}